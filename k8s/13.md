# Outputs

```
PS D:\git\core-course-labs\k8s\helm\app-python> kubectl get po,sts,svc,pvc
NAME               READY   STATUS    RESTARTS   AGE
pod/app-python-0   1/1     Running   0          22s
pod/app-python-1   1/1     Running   0          22s

NAME                          READY   AGE
statefulset.apps/app-python   2/2     22s

NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
service/app-python   NodePort    10.100.54.188   <none>        5000:31876/TCP   22s
service/kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP          13d

NAME                                                STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/counter-python-app-python-0   Bound    pvc-aeb5dcdc-bf16-4eff-aee4-35eb50d8b47d   10Mi       RWO            standard       22s
persistentvolumeclaim/counter-python-app-python-1   Bound    pvc-12d8da0e-77b9-4a49-a4f0-a466631cb8cc   10Mi       RWO            standard       22s
```

```
PS D:\git\core-course-labs\k8s\helm\app-python> kubectl exec app-python-0 -- cat /data/visits.txt
10
```

```
PS D:\git\core-course-labs\k8s\helm\app-python> kubectl exec app-python-1 -- cat /data/visits.txt

6
```

# Ordering Guarantee and Parallel Operations

## Explain why ordering guarantees are unnecessary for your app.

Because my python app don't have any state which must dependent on ordering of pods.

## Implement a way to instruct the StatefulSet controller to launch or terminate all Pods in parallel.

Just add `podManagementPolicy` in statefulset.yaml:

```
spec:
    podManagementPolicy: Parallel
```

# Update Strategies

[Source](https://www.weave.works/blog/kubernetes-deployment-strategies)

- Rolling Strategy Deployment:
  - The rolling deployment strategy involves gradually replacing pods of the previous version with pods of the new version, one by one. This is the standard deployment to Kubernetes and is performed without any cluster downtime. The process waits for new pods to become ready before scaling down the old ones, allowing for potential aborts if issues arise. The YAML definition file is used to specify the new image in the deployment.
- Recreate:

  - In a recreate deployment, all old pods are terminated simultaneously and replaced with new ones. This is a straightforward deployment strategy, but it results in a momentary downtime during the switch from the old to the new version.

- Blue/Green (or Red/Black) Deployments:

  - Blue/Green deployments involve deploying both the old (blue) and new (green) versions simultaneously. Users interact with the old version initially, while the new version is available for testing. Once the new version is tested and approved, a switch is made, directing users to the new version. This strategy allows for quick rollback if issues are discovered.

- Canary Deployments:

  - Canary deployments are a controlled and progressive approach to releasing new functionality. It involves releasing a new version to a subset of users or servers, monitoring for errors or issues. If successful, the new version gradually rolls out to the entire infrastructure. This strategy is more controlled than blue/green deployments and can be implemented using Kubernetes resources or service meshes like Istio.

- Canary Deployments with Flagger:

  - Using Flagger for canary deployments automates the promotion process. It utilizes Istio or App Mesh for traffic routing and shift and Prometheus metrics for analysis. Flagger gradually shifts traffic to the canary version while measuring key performance indicators. Based on the analysis, the canary is either promoted or aborted, and the results are communicated, often via Slack.

- Dark Deployments or A/B Deployments:

  - Dark deployments, also known as A/B testing, involve releasing a new feature to a small set of users without their awareness. This allows for monitoring user interactions, conversions, and other metrics to assess the impact of the new feature. Feature toggles and other tools are commonly used in this strategy.

- Flagger and A/B Deployments:
  - Flagger can also be used for A/B testing scenarios by routing traffic to the canary based on HTTP match conditions. This involves using HTTP headers or cookies to target specific user segments, particularly useful for front-end applications requiring session affinity. Flagger offers functionality for A/B deployments in addition to its canary deployment capabilities.
